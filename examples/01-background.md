项目背景
========
本章主要介绍Arbiter调度器项目的背景，并对该项目面向的问题域进行讨论。在讨论过程中，我们会常常与Unix单机系统进行类比。

大体来看，利用数据指导商业活动已经成了目前各行各业的趋势。以[Hadoop](http://hadoop.apache.org/)为代表的开源社区
也已经为我们提供了较为成熟的数据存储与处理的基础设施。基于这些开源设施，不同的公司各自建设了不同的数据平台、数据仓库系
统，以提高数据的管理与使用效率。在这些数据平台中，有一个重要的服务，就是对例行作业的调度。这些例行作业可能在做数据ETL，
可能在做中间数据建模，也可能在生成运营或管理人员直接查看的核心报表。在建设内部数据平台的过程中，我们发现，目前开源社区
并没有一个被广泛使用的基于数据依赖的调度器。我们于是就启动了Arbiter项目，期望在建设内部数据平台的同时，也能为开源社区
提供一个高质量的数据依赖调度器的选择。

问题域
--------
本节我们讨论Arbiter面对的问题域。

对调度器最直接的需求就是， **“按照某个预先指定的周期执行指定的作业”** 。这就是调度器的核心工作了。从这个角度来看，
unix的crontab忠实地解决了核心需求。但是我们经常觉得crontab还不够好用，我们来看看到底哪里不好用。

1.  作业部署

    首先，用户要找一台能够使用的执行机，这台机器应该是一个比较稳定的、长期开机的服务器。了解这台服务器的相关特征。如：

    -   主目录是不是和别人共享的。
    -   机器负载重不重，分布情况是什么。
    -   能使用的磁盘空间有多少，默认的/tmp下有多少空间。
    -   core文件会被放到什么地方。
    -   等等。

    其次，用户需要手工部署作业及其执行环境。这本身就是一个繁琐而且容易出错的过程。如：

    -   部署所有的依赖库、工具，设置好正确的环境变量（如PATH和LIBRARY_PATH, XXXX_HOME等)。
    -   部署正确版本的并且在正确的环境下编译出来的可执行程序、部署这个作业的依赖文件等。
    -   避免不同作业之间对依赖、对执行机负载的冲突。
    -   想办法及时清理作业的中间数据。
    -   等等。

    最后，期待这台服务器不要宕机。一旦需要将作业迁移到另一台执行机，所有这些事情都要重新做一遍。

    比较好的方式是，用户只需要描述一次作业的依赖与环境，并提供VCS的地址与版本，系统就能够自动地编译并部署这个作业。
    用户不用关心这个作业是在什么机器上执行的，系统会保证它一定在某台机器上执行了。

1.  作业执行信息通知与报警

    用户可能希望知道例行作业每次执行的情况，以及结果的一些统计信息。这些信息包括：

    -   当前状态：

        - 等待。
        - 运行，包括动态优先级、进度等详细信息。
        - 阻塞，包括被谁阻塞等详细信息。

    -   结果状态

        - 成功。
        - 失败。
        - 延时，由于某些原因，没有在 “规定的时间”之前完成。

    -   任务执行结束后关于结果的一些统计信息。如更新了多少记录，X计数器的值是多少等。

    对于crontab而言，想要看这些信息，就只能登录到执行机上通过ps、日志等方式查看。对于最终的执行状态和统计信息，还可
    以通过自行写脚本或增加代码逻辑来自动发送邮件来完成。

    事实上这些逻辑具有较高的通用性，比较好的方式是由调度器统一提供。

1.  数据依赖

    目前开源社区被较多使用的调度器，[Azkaban](http://azkaban.github.io)和[Oozie](http://oozie.apache.org)
    都是作业依赖的调度器，即用户是通过指定“作业A依赖作业B”来描述依赖关系的。crontab无法指定依赖，预定的时间一到，
    相应的任务一定会被启动。

    作业依赖并非“真依赖”，数据依赖，准确说是“写后读（RAW）”形式的数据依赖，才是真依赖。关于真依赖的解释，请参考
    [数据冒险] [data-hazards] 。简单来讲，一个作业的本质目的是产生某些输出。如果一个作业没有任何输出，那么它除了
    消耗资源外就没有任何用处了。一个作业A依赖于另一个作业B的本质也是，A需要使用B的输出作为自己的输入。否则，这个依赖
    也没有任何意义，因为在有资源的情况下，A完全可以和B同时执行而不需要等待B执行完成后再执行。

    对于Azkaban和Oozie而言，让用户指定作业依赖可能存在几个问题：

    -   如果作业A和作业B同时依赖作业C，调度器无法判断应该执行一次C，然后再执行A和B，还是应该为A和B各执行一次C。
        事实上，这两种情况都是可能的。要么调度器采用一个保守策略，即为A和B各执行一次C，要么就需要用户指定一个选择。
        第一种方式无疑造成较大的资源浪费，第二个方式则增加用户需要了解的细节（想象一下，C是部门cc计算得到某基础数据
        的作业，A是部门aa生成报表的作业，B是部门bb的挖掘作业。部门B的人在使用调度器时，还需要同时了解作业C和A的逻辑
        以及调度配置，才能正确地配置自己的作业的调度信息。

    -   额外的耦合，仍然做出前面的假设，作业A和作业B同时依赖作业C。有一天，cc部门决定重构C作业以提高效率，把它拆分成
        了两个作业C1和C2，仍然生成同样的基础数据（毕竟，数据本身才是大家依赖的东西，只要数据不变，大家的代码就可以不
        变）。这时，采用作业依赖的话，A和B就要重新调整调度信息，更新依赖。这种更新原本可以通过数据依赖避免。

    -   “假依赖”。指定作业依赖，当依赖图复杂的时候，很容易引入“假依赖”。即，作业A和作业B原本可以被并行执行的，但由于
        不小心指定了它们的依赖，或者通过某组其它任务（D1，D2...）间接导致了A和B的依赖，进一步导致，即便在资源充足
        的情况下，调度器也不能同时调度A和B。无法发现真正的依赖，会较大地限制调度器的调度灵活性，影响到“资源利用率”，
        “任务执行时间SLA”，“动态优先级”等其它几个调度目标的达成。

    “作业依赖”的方式，在每份数据都只有少数几个作业使用，而且这几个作业的开发者也是紧密配合并沟通的情况下，不会造成太大
    的问题。但是，当我们建设一个供若干个部门使用、存在大量数据共享的数据平台的时候，这种方式带来的资源浪费、维护与沟通
    代价的问题就会凸显出来。crontab无法指定依赖，造成的额外工作量更多。

    比较好的方式是指定“数据依赖”，即作业A的开发者仅仅指定作业A依赖的数据（输入数据），只要数据格式不变（或者只发生兼容
    性变化），这个开发者不用关心哪些作业以什么方式产生了这些输入数据，也不用关心还有哪些作业与作业A依赖同样的输入数据，
    当然，更不用关心那些作业的变化，只要关心自己的作业A即可。与此同时，调度器也很开心，因为它可以发现所有作业之间的真
    依赖，得到了最大的调度灵活性。

1.  作业优先级与作业完成时间保证

    资源总是不够的。当一个人有多个作业的时候，通常会出现一个需求，即告诉调度器，哪些作业优先级较高，当资源不够的时候，
    优先保证那些高优先级作业的完成时间。比如，我有三份数据，一份给我自己看，一份给上司看，一份推送到线上服务。
    毫无疑问，我希望调度器能够保证，推送线上服务的数据每天4点必须完成，给上司看的报表早上9点到10点完成就行，给我自己
    看的报表当天下班前完成就行。

    我们发现，这里与crontab或yarn的调度不同，它们是为任务指定一个静态优先级。而我们是在考虑完成时间的情况下，综合
    静态与动态优先级。比如，作业A需要X资源执行30分钟，它的完成时间是17：00，如果在14：00的时候，它的所有依赖都已经
    满足了，它就处于可运行状态，此时，它的优先级是很低的，如果资源有空闲，执行它（没人会讨厌系统多给了一些资源给自己，
    提前完成了自己的任务）。但如果此时已经到16：10了，而它仍然在阻塞，那么我们就需要提高它的优先级，同时还需要找到阻塞
    它的作业（作业A依赖这些作业），并且把这些作业的优先级也提高，递归下去。

1.  资源利用率最大化，这显然是我们的目标

1.  执行机的管理与Failover

    当一个系统中有大量作业的时候，调度器可能无法使用一台执行机满足执行需求，此时，我们需要管理一组执行机。

    只要是计算机，就有可能宕机。如果一个执行机宕机，有可能导致它上面执行的任务的失败或者丢失状态。调度器需要对执行机
    做Failover。将执行机的失败向用户屏蔽。

1.  资源统计与计费。调度器天然可以统计每个用户的每个作业使用的资源情况。

在增加了上面这些改进之后，我们似乎看到了一个比较好用的调度器。这些问题也正是Arbiter要解决的。

Arbiter思路
-----------
本节我们讨论Arbiter模糊的设计思路，这些思路是后续严谨设计的基础。

我们首先来定义两个概念，此后，我们严格地区分使用它们：

-   **Job，作业** ，一个静态实体，类似于unix操作系统中的一个可执行程序。
-   **Task，任务** ，一个作业的一次执行，类似于unix操作系统中的一个进程。

好，看起来很清晰。比如，我定义了一个每小时执行一次的作业，我把它的定义提交给调度器，调度器每天就会执行它24次，每次执行
都是一个任务。作业只有一个，但它的执行实例，任务，却可以有很多个。执行的状态信息和执行结果的统计信息是关联在任务上的。

下一个问题是，调度器需要知道什么信息，才能从一个Job生成一个Task？即Job定义应该包含哪些内容？

调度周期肯定是一个信息，这也是核心功能。我们就先来看看怎么指定调度周期信息。首先，手动执行，这个在开发测试阶段，或某些
特殊情况下会需要，用户会手动触发一个任务的执行。其次，也是最常见的情况，以某个周期自动执行，如1分钟、2小时、3天、4周等，
此时，又会有一些细节：

-   以哪个时间点为基准时间算周期？好吧，我们需要指定一个StartTime，如"今天13：00：00"开始，或者从“提交成功时再加xx
    秒开始”。

-   如果作业的执行时间比周期还长要怎么处理？
    这涉及到我们怎么理解周期“每天执行一次”，等等，换个更明显的例子，怎么理解周期“每分钟执行一次”。

    -   fix-rate
        crontab的语义其实是fix-rate语义，即，如果用户指定调度是“每分钟执行一次”，那么它会忠实地每隔一分钟（以上一次
        启动一个进程的时间点开始算）启动一个新进程来执行，而不管前一分钟的那个是不是执行完了。这个语义也是默认的语义。

    -   fix-delay
        这是另一种语义，即，如果用户指定调度是“每分钟执行一次”，那么，它会在每个任务执行结束后，等1分钟，再启动下一个
        任务。这种情况通常在一些数据更新操作或监控作业中使用。

    这两个的区别请考虑，如果一个作业指定了，“每分钟执行一次”，但是它本身每次执行都要花2分钟，那么，在30分钟里面，
    fix-rate启动了30个任务，而fix-delay则仅仅启动了10个。

-   一个Job是不是要永远执行下去？当然不是，但不再执行这件事情一般不会事先确定，手动也不麻烦，所以这个可以先让用户手动
    搞吧，定义数据结构时如果方便，可以考虑加入“最多执行次数”和“停止时间”。执行x次之后，或者当前时间超过了指定的停止
    调度时间，该Job就不再触发Task。

有了调度周期，我们还需要哪些东西？类比于unix的程序。

-   启动进程还需要一些额外的信息，如输入输出，环境变量，命令行参数等。输入输出比较特殊，我们放在一个单独的条目中说。我
    们需要能够在Job定义中指定环境变量、命令行参数。注意，这些可能不是静态的，而是随着时间变化的函数。我们提供一些“宏”
    来让用户表达这种变化性。

-   输入输出。由于调度器要知道“真依赖”，所以，调度器需要知道一个Job的输入与输出，把它们和其他的命令行参数区分出来，
    同样，输入和输出也是随着时间变化的，也要有相应的宏来使用。我们把所有的输入输出都抽象成某个“数据库”的“表”的“分区”。
    最经常随时间变化的东西就是“分区”。一个任务可以有n个输入和m个输出，这个要以某种约定好形式在命令行参数中标记出来。
    比如 `appevent ${DATE} ${in:abc/date=${DATE}} ${out:xyz/efg/date=${DATE}} ${inout:mapping} ...`
    对于每一类输入，我们需要一个插件用于检查它是否就绪。如，hdfs某个路径是否存在并且有_SUCCESS标记文件，hbase的某张
    表是否有某个family:column等。

    这里有一个考虑，命令行仍然是一个“完整的命令行”，用户程序通过命令行位置参数获得输入输出参数，这样避免了对用户程序的
    “侵入”。同时也比较直观。

    **避免对用户程序的侵入** 这个原则贯穿整个调度器的设计。即，用户不需要import调度器的某个库或在程序代码中添加某些
    逻辑才能使用调度器。当用户的程序脱离调度器的时候，仍然是一个完整合法可独立执行的程序。

-   一个程序除了输入输出之外，可能还需要一些依赖文件，本质上这些文件也是输入，但它们有些特殊性，就是任务希望它们就在
    “本地”当前目录。如果我们以输入的方式交给用户程序，那用户程序做的动作就是将它们下载到本地。所以，为了方便起见，我们
    直接替用户程序下载到执行目录即可。比如，某些.so文件、字典文件等。这些文件有一个约束：“可读可执行，但不可以写”。

-   如何报告任务执行的状态、进度、执行结果的统计信息？这同样需要约定一个规范。状态很容易定义，0表示成功，非0表示出现了
    某些错误。任务可以在stderr中输出任意的信息（文本信息，LineBuffer模式）。但，如果某一行是以`@arbiter `开始的，
    调度器则认为这是与它在进行通讯。这些行会从最终的stderr中删去（只有调度器能看到），在这些行里面，调度器定义了几个
    标准的命令，如`progress 0.123`表示输出这一行的时候，进度在12.3%左右；`counter name = value`表示输出一个
    counter值；`counter name += value`表示在某个counter上累加值；`attach file`表示在最终的通知邮件中包含一个
    指定的文件。最终通知邮件默认包含stdout，默认不包含stderr。如果需要包含stderr，使用`attach stderr`命令。

    这里的设计看起来adhoc，但其实仍然是为了减少对用户程序的侵入。

-   对优先级、完成时间需求、执行资源需求的描述。

调度，必然涉及到资源。这里，我们给出资源的描述。资源从所有方维度分为两种：

-   作业需要的资源
-   系统还有的资源

资源从类别方面又分为两类：

-   单机资源（执行机资源，对应于运行命令的那个机器）
-   集群资源（分布式资源）

上面两个维度供描述了4种类型的资源，在每一种类型中，我们关心的具体资源为（CPU、MEM、NET、DISK）。其中，每项都由
capacity和duration两个指标衡量。这些衡量都是可选的。对于需求，capacity包含(minimal, expected)两个值，对于系统
资源描述，capacity包含(expected, maximal, used)。系统capacity是被不断更新的。

至此，我们的调度器的基本模样似乎已经勾画出来了。

API的形式
---------
选择WebService还是RPC？由于调度器服务本身并不会有高并发或大数据传输，所以公共API采用RESTful的WebService应该是一个
比较好的选择。（架构设计可以保证，我们可以非常方便地增加一种新的API。）WebService API中交换数据的格式都是JSON。

核心功能接口：

-   GET /jobs/job_name: 查询一个job的静态信息
-   GET /jobs/job_name/tasks?filter=abc: 查询一个job的task相关信息
-   PUT /jobs/job_name: 提交或更新一个job的信息.

开发模式
--------
迭代式开发，从最小可用功能集合开始作为0.1版。系统的开发基于akka actor分布式框架。数据库访问采用slick。RESTful服务
采用spray。

开发过程：

1. 定义模块类，以及它们的API，不实现。
1. 实现单元测试，和集成测试，跑通全红结果。
1. 逐个实现模块类。


[data-hazards]: http://en.wikipedia.org/wiki/Hazard_%28computer_architecture%29#Data_hazards
